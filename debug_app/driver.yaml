apiVersion: v1
kind: Pod
metadata:
  labels:
    spark-app-selector: {appid}
    spark-role: driver
  name: {appname}
  namespace: spark-dev
  selfLink: /api/v1/namespaces/spark-dev/pods/{appname}
spec:
  containers:
  - args:
    - driver-py
    - --properties-file
    - /opt/spark/conf/spark.properties
    - --class
    - org.apache.spark.deploy.PythonRunner
    env:
    - name: SPARK_DRIVER_BIND_ADDRESS
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: K8S_NAMESPACE
      value: spark-dev
    - name: LOGPATH
      value: /srv/log
    - name: SPARK_LOCAL_DIRS
      value: /var/data/spark-58c2dd88-e4d2-4f16-9381-531937827f9e
    - name: PYSPARK_PRIMARY
      value: hdfs:///user/hadoop/etlsdk/run.py
    - name: PYSPARK_MAJOR_PYTHON_VERSION
      value: "3"
    - name: PYSPARK_APP_ARGS
      value: {command} --config hdfs://tmp/ting.wu/k8s_press/{job_id}.json
    - name: SPARK_CONF_DIR
      value: /opt/spark/conf
    image: registry-vpc.cn-hangzhou.aliyuncs.com/eigenlab/data_pipeline:test_conf
    imagePullPolicy: Always 
    securityContext:
      capabilities:
        add: ["SYS_PTRACE"]
    name: spark-kubernetes-driver
    ports:
    - containerPort: 7078
      name: driver-rpc-port
      protocol: TCP
    - containerPort: 7079
      name: blockmanager
      protocol: TCP
    - containerPort: 4040
      name: spark-ui
      protocol: TCP
    resources:
      limits:
        memory: 4000Mi
      requests:
        cpu: "0.5"
        memory: 4000Mi
    terminationMessagePath: /spark-dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /srv/log
      name: log
    - mountPath: /var/data/spark-58c2dd88-e4d2-4f16-9381-531937827f9e
      name: spark-local-dir-1
    - mountPath: /opt/spark/conf
      name: spark-conf-volume
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: spark-token-k7l88
      readOnly: true
  dnsPolicy: ClusterFirst
  imagePullSecrets:
  - name: aliyun-registry
  restartPolicy: Never
  schedulerName: default-scheduler
  securityContext: 
  serviceAccount: spark
  serviceAccountName: spark
  terminationGracePeriodSeconds: 30
  nodeSelector:
    role: spark
    env: spark-dev
    driver: driver
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: log
    persistentVolumeClaim:
      claimName: spark-dev-log
  - emptyDir: 
    name: spark-local-dir-1
  - configMap:
      defaultMode: 420
      name: {appname}-conf-map
    name: spark-conf-volume
  - name: spark-token-k7l88
    secret:
      defaultMode: 420
      secretName: spark-token-k7l88
